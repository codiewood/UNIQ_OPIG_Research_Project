#!/usr/bin/env python3
# coding: utf-8

# In[2]:

import gzip, json, re, sys
from collections import Counter

oas_file = str(sys.argv[1])

meta_line = True
sequence_data = []
for line in gzip.open(oas_file, 'rb'):
    if meta_line == True:
        metadata = json.loads(line)
        meta_line = False
        continue
    
    #Parse actual sequence data.
    basic_data = json.loads(line)
    sequence_data.append(basic_data)
    
    #IMGT-Numbered sequence.
    d = json.loads(basic_data['data'])
    sequence_data[-1]['data'] = d
    
print("The data we will look at is from {}, with metadata {}".format(oas_file,metadata))
print("""
      ==================
      """)
#%%

def maximum_valued_key(dictionary):
    values = list(dictionary.values())
    keys = list(dictionary.keys())
    return keys[values.index(max(values))]

def sort_alphanumerically(l): 
    convert = lambda text: int(text) if text.isdigit() else text.lower() 
    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] 
    return sorted(l, key = alphanum_key)

# In[5]:

def cdrh3_sequences():
    cdrh3_sequences = []
    for data in sequence_data:
        cdrh3 = data['data']['cdrh3']
        cdrh3_sequences.append(cdrh3)
    return cdrh3_sequences

def cdrh3_sequence_counter(cdrh3_sequences):
    cdrh3_sequence_count = {}
    for cdrh3 in cdrh3_sequences:
        key = json.dumps(cdrh3, sort_keys=True)
        if key in cdrh3_sequence_count:
            cdrh3_sequence_count[key] += 1
        else:
            cdrh3_sequence_count[key] = 1
    return cdrh3_sequence_count

cdrh3_sequence_count = cdrh3_sequence_counter(cdrh3_sequences())
most_common = maximum_valued_key(cdrh3_sequence_count)
occurences = cdrh3_sequence_count[most_common]

print("The CDR-H3 sequence which was most common was {}, which appeared {} times.".format(most_common,occurences))
print("""
      ==================
      """)    
# In[7]:

redundant_sequences = metadata['Size']

def combine_regions(data):
    regions = ['fwh1','cdrh1','fwh2','cdrh2','fwh3','cdrh3','fwh4']
    combined_sequence = {}
    for region_name in regions:
        region_sequence = data['data'][region_name]
        combined_sequence.update(region_sequence)
    return combined_sequence 

def find_amino_acids(position):
    amino_acids = []
    for data in sequence_data:
        full_sequence = combine_regions(data)
        for i in range(int(data['redundancy'])):
            if position in full_sequence:
                amino_acids.append(full_sequence[position])
            else:
                amino_acids.append('Unused')
    return amino_acids 

def generate_positions():
    all_positions = set()
    for data in sequence_data:
        full_sequence = combine_regions(data)
        positions_used = list(full_sequence.keys())
        for position in positions_used:
            all_positions.add(position)
    position_list = sort_alphanumerically(list(all_positions))
    return position_list #list of all possible positions in order of occurence

position_list = generate_positions()

def amino_acid_percent(position):
    amino_acids = find_amino_acids(position)
    amino_acid_count = Counter(amino_acids)
    for amino_acid in amino_acid_count:
        frequency = (100*amino_acid_count[amino_acid])/redundant_sequences
        amino_acid_count[amino_acid] = round(frequency,2)
    amino_acid_frequency = dict(amino_acid_count)
    return amino_acid_frequency

for position in position_list:
    print("""For position {}, we see that the amino acids seen and their respective percentage usages, including sequence repeats, are:
    {}.
    """.format(position,amino_acid_percent(position)))

consensus_sequence = {}
for position in position_list:
    consensus_sequence[position] = maximum_valued_key(amino_acid_percent(position))
print("""
      ==================
      """)
print("""The consensus sequence for this data, including sequence repeats, is:
{}""".format(consensus_sequence))

